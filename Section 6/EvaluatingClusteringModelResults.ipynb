{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Clustering Model Results\n",
    "*Curtis Miller*\n",
    "\n",
    "Deciding whether a clustering scheme is \"good\" is more difficult to *define* compared to evaluation of learning algorithms. This is because the data is unlabeled. There is no \"truth\" to compare against to decide if the clusters split the data. Thus choosing between clustering schemes is largely subjective.\n",
    "\n",
    "However we can impose criteria we would like a clustering scheme to satisfy. For instance we may want clusters to minimize within-cluster sum of squared \"errors\" (distance from the centroid) but not at the expense of having lots of clusters. We may decide then that the optimal number of clusters is the number of clusters that makes measure of error small without having many clusters. Other evaluation schemes exist as well.\n",
    "\n",
    "We will look at evaluating these schemes when clustering the iris data using $k$-means. The two approaches I will show are the \"elbow\" approach and silhouette analysis.\n",
    "\n",
    "## Clustering the Iris Dataset\n",
    "\n",
    "The first example will demonstrate using $k$-means clustering for the iris dataset. I first load in that dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_obj = load_iris()\n",
    "iris_data = iris_obj.data\n",
    "species = iris_obj.target\n",
    "iris_data[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(iris_data[:, 0], iris_data[:, 1], c=species, cmap=plt.cm.brg)\n",
    "plt.xlabel(\"Sepal Length\")\n",
    "plt.ylabel(\"Sepal Width\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I import the `KMeans` object to perform $k$-means clustering, and then apply the method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irisclust = KMeans(n_clusters=3, init='random')    # Three clusters with cluster centers chosen as random dataset points\n",
    "irisclust.fit(iris_data)\n",
    "irisclust.cluster_centers_    # The coordinates of cluster centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the clustering\n",
    "plt.scatter(iris_data[:, 0], iris_data[:, 1], c=irisclust.predict(iris_data), cmap=plt.cm.brg)\n",
    "plt.scatter(irisclust.cluster_centers_[:, 0], irisclust.cluster_centers_[:, 1],\n",
    "            c=irisclust.predict(irisclust.cluster_centers_), cmap=plt.cm.brg, marker='^', s=200,\n",
    "            edgecolors='k')\n",
    "plt.xlabel(\"Sepal Length\")\n",
    "plt.ylabel(\"Sepal Width\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the \"Elbow\"\n",
    "\n",
    "Consider a plot of the sum of within-cluster squared errors:\n",
    "\n",
    "$$\\sum_{k=1}^{K} \\sum_{i_k = 1}^{N_k} \\|x_{i_k} - \\mu_{k}\\|^2$$\n",
    "\n",
    "We want this number to be small, but we also want the number of clusters to be small. So we plot this quantity and choose the number of clusters $K$ that corresponds to the \"elbow\" of the plot.\n",
    "\n",
    "The function below creates such a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wcsse_plot(data, max_clusters):\n",
    "    \"\"\"Plots sum of within-cluster sum of squared errors for clusters up to max_clusters for dataset data\"\"\"\n",
    "    wcsse = np.arange(max_clusters) + 1\n",
    "    for k in wcsse:\n",
    "        wcsse[k - 1] = KMeans(n_clusters=k).fit(data).inertia_    # inertia is the sum described above\n",
    "    plt.plot(np.arange(max_clusters) + 1, wcsse, marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcsse_plot(iris_data, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where is the elbow? We know that there are actually three species of iris flowers. Based on this plot, three clusters isn't a bad choice; this is around where the \"elbow\" is.\n",
    "\n",
    "## Silhouette Analysis\n",
    "\n",
    "Let $a(i)$ be the average dissimilarity of data point $i$ to all other data points in its cluster, and $b(i)$ the average dissimilarity of data point $i$ to the data points in the next nearest cluster (other than the cluster to which data point $i$ has been assigned). The silhouette score for data point $i$ is then:\n",
    "\n",
    "$$s(i) = \\frac{b(i) - a(i)}{\\max \\left(a(i), b(i)\\right)}$$\n",
    "\n",
    "This is a number between -1 and 1. 1 means that data point $i$ is very different from clusters other than the cluster to which it has been assigned, while -1 (and any number less than zero) suggests that data point $i$ is in the wrong cluster. A value of 0 suggests that data point $i$ is on the border of belonging to one of at least two clusters.\n",
    "\n",
    "If we average the silhouette scores of each data point, we get the average silhouette score. We prefer this number not to be small since this suggests that clusters are not highly dissimilar; there are likely too many.\n",
    "\n",
    "We can use the silhouette scores to construct a silhouette plot. **scikit-learn** provides functions, `silhouette_samples()` and `silhouette_score()`, that computes the silhouette score of each data point and the average silhouette score, respectively. These can be used to construct a silhouette plot. I have written a function for doing so. (The code for writing this function was strongly influenced by [this example](http://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html#sphx-glr-auto-examples-cluster-plot-kmeans-silhouette-analysis-py) provided by **scikit-learn**'s documentation.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_samples, silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def silhouette_plot(data, labels, metric=\"euclidean\", xticks = True):\n",
    "    \"\"\"Creates a silhouette plot given a dataset and the labels corresponding to cluster assignment, and reports the\n",
    "       average silhouette score\"\"\"\n",
    "    silhouette_avg = silhouette_score(data, labels,\n",
    "                                      metric=metric)    # The average silhouette score over the entire sample\n",
    "    sample_silhouette_values = silhouette_samples(data, labels,\n",
    "                                                  metric=metric)    # The silhouette score of each individual data point\n",
    "    \n",
    "    # This loop creates the silhouettes in the silhouette plot\n",
    "    y_lower = 10    # For space between silhouettes\n",
    "    for k in np.unique(labels):\n",
    "        cluster_values = sample_silhouette_values[labels == k]\n",
    "        cluster_values.sort()\n",
    "        nk = len(cluster_values)\n",
    "        y_upper = y_lower + nk\n",
    "        color = cm.spectral(float(k) / len(np.unique(labels)))\n",
    "        plt.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, cluster_values,\n",
    "                          facecolor=color, edgecolor=color)\n",
    "        plt.text(-0.05, y_lower + 0.5 * nk, str(k))\n",
    "        y_lower = y_upper + 10\n",
    "    \n",
    "    plt.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "    if xticks:\n",
    "        plt.xticks([-0.1, 0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "    plt.yticks([])\n",
    "    plt.xlabel(\"Silhouette Score\")\n",
    "    plt.ylabel(\"Cluster\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"The average silhouette score is\", silhouette_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_plot(iris_data, irisclust.predict(iris_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at a silhouette plot we do not want to see a cluster with most all (or nearly all) observations below the average silhouette score (as indicated by the red dashed line). This occurance would suggest a bad clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nclust_silhouette_kmeans(data, n_clusters):\n",
    "    \"\"\"A function for finding the k-means clustering with n clusters for a dataset and creating the corresponding silhouette\n",
    "       plot\"\"\"\n",
    "    labels = KMeans(n_clusters=n_clusters, init='random').fit_predict(data)\n",
    "    silhouette_plot(data=data, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nclust_silhouette_kmeans(iris_data, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nclust_silhouette_kmeans(iris_data, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nclust_silhouette_kmeans(iris_data, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nclust_silhouette_kmeans(iris_data, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last two silhouette plots suggest that 4 and 5 clusters are not the right amounts since we end up with clusters whose silhouette scores are almost all below the mean. Either two or three clusters appear to be appropriate.\n",
    "\n",
    "These analyses suggest that either two or three clusters are appropriate. We know that there are three species in this dataset but without this information we may need to decide which is appropriate. (It appears that one species, setosa, is very different from the other two. Look at plots of the flowers' petal length and petal width if you don't believe me.) Any number above three, though, is clearly inappropriate, as indicated by these plots."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
